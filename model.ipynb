{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading csv file\n",
    "#reading myData\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#loading csv file from zip\n",
    "archive = zipfile.ZipFile('/home/carnd/simulation_data/allDataFinal.zip', 'r')\n",
    "csvFile = archive.open('driving_log.csv')\n",
    "\n",
    "\n",
    "lines=[] #reading csv files\n",
    "y=[] #the output for the steering angle\n",
    "X=[] #list for image output\n",
    "#reading csv file\n",
    "csvReader = pd.read_csv(csvFile, header=None)# the myData.zip file does not use headers\n",
    "correction = 0.2\n",
    "\n",
    "for line in csvReader.iterrows():\n",
    "    lines.append(line[1])\n",
    "    '''\n",
    "    center_img = archive.open('IMG/' + line[1][0].split('IMG\\\\')[-1])\n",
    "    center_img = plt.imread(center_img) \n",
    "    \n",
    "    left_img = archive.open('IMG/' + line[1][1].split('IMG\\\\')[1])\n",
    "    left_img = plt.imread(left_img)\n",
    "    \n",
    "    right_img = archive.open('IMG/' + line[1][2].split('IMG\\\\')[1])\n",
    "    right_img = plt.imread(right_img)\n",
    "    \n",
    "    #X.append(np.concatenate((center_img, left_img, right_img),axis=2)) #creating a 9 channel input to be used by the network \n",
    "    X.append(center_img)\n",
    "    y.append(float(line[1][3]))\n",
    "    \n",
    "    X.append(left_img)\n",
    "    y.append((float(line[1][3])+correction))\n",
    "    \n",
    "    X.append(right_img)\n",
    "    y.append((float(line[1][3])-correction))\n",
    "    \n",
    "img_shape = X[0].shape\n",
    "\n",
    "#convert inputs and outputs to numpy array for keras\n",
    "X_train=np.array(X)\n",
    "y_train=np.array(y)\n",
    "'''\n",
    "img_shape = plt.imread(archive.open('IMG/' + lines[0][0].split('IMG\\\\')[-1])).shape\n",
    "#train_samples, validation_samples = train_test_split(lines, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranges = np.zeros(10, np.int16)\n",
    "\n",
    "for line in lines:\n",
    "    steering = line[3]\n",
    "    for i in range(0,10):\n",
    "        if(steering>(1-0.2*(i+1)) and steering<(1-0.2*i)):\n",
    "            ranges[i]= ranges[i]+1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKBCDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdce9c785f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.linspace(0.9,-0.9,10),ranges, 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "for i in reversed(range(len(lines))):\n",
    "    steering = float(lines[i][3])\n",
    "    if(steering>0 and steering<0.2):\n",
    "        keep_probs = random.random();\n",
    "        if(keep_probs>0.45):\n",
    "            del lines[i] \n",
    "    elif(steering>-0.2 and steering<=0):\n",
    "        keep_probs = random.random();\n",
    "        if(keep_probs>0.22):\n",
    "            del lines[i] \n",
    "    elif(steering>-0.4 and steering<=-0.2):\n",
    "        keep_probs = random.random();\n",
    "        if(keep_probs>0.8):\n",
    "            del lines[i] \n",
    "    elif(steering<-0.8 or steering>0.8):\n",
    "        for j in range(8):\n",
    "            lines.append(lines[i])\n",
    "    elif(steering<-0.6 or steering>0.6):\n",
    "        for j in range(2):\n",
    "            lines.append(lines[i])\n",
    "    elif(steering<-0.5 or steering>0.5):\n",
    "        for j in range(2):\n",
    "            lines.append(lines[i])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdcff2e32e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranges = np.zeros(10, np.int16)\n",
    "\n",
    "for line in lines:\n",
    "    steering = line[3]\n",
    "    for i in range(0,10):\n",
    "        if(steering>(1-0.2*(i+1)) and steering<(1-0.2*i)):\n",
    "            ranges[i]= ranges[i]+1\n",
    "            break\n",
    "plt.bar(np.linspace(0.9,-0.9,10),ranges, 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = shuffle(lines)\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_samples), len(validation_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir0 = 'IMG/' + lines[0][0].split('IMG')[-1]\n",
    "if dir0 in archive.namelist():\n",
    "    print('yes')\n",
    "#print(archive.namelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generator for myData\n",
    "\n",
    "#utilizing generators for reading data\n",
    "def generator(archive_in, samples, batch_size=32, augment=False):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "        \n",
    "            if(augment):\n",
    "                batch_samples = samples[offset:offset+math.ceil(batch_size/2)]\n",
    "            else:\n",
    "                batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            #loading files\n",
    "            for batch_sample in batch_samples:\n",
    "                dir1 = 'IMG/' + batch_sample[0].split('IMG\\\\')[-1]\n",
    "                dir2 = 'IMG/' + batch_sample[0].split('IMG/')[-1]\n",
    "                if dir1 in archive.namelist():\n",
    "                    name =  archive_in.open(dir1)\n",
    "                elif dir2 in archive.namelist():\n",
    "                    name =  archive_in.open(dir2)\n",
    "                center_image = plt.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                '''\n",
    "                dir1 = 'IMG/' + batch_sample[1].split('IMG\\\\')[-1]\n",
    "                dir2 = 'IMG/' + batch_sample[1].split('IMG/')[-1]\n",
    "                if dir1 in archive.namelist():\n",
    "                    name =  archive_in.open(dir1)\n",
    "                elif dir2 in archive.namelist():\n",
    "                    name =  archive_in.open(dir2)\n",
    "                left_image = plt.imread(name)\n",
    "                left_angle = float(batch_sample[3]) + correction\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                \n",
    "                dir1 = 'IMG/' + batch_sample[2].split('IMG\\\\')[-1]\n",
    "                dir2 = 'IMG/' + batch_sample[2].split('IMG/')[-1]\n",
    "                if dir1 in archive.namelist():\n",
    "                    name =  archive_in.open(dir1)\n",
    "                elif dir2 in archive.namelist():\n",
    "                    name =  archive_in.open(dir2)\n",
    "                right_image = plt.imread(name)\n",
    "                right_angle = float(batch_sample[3]) - correction\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                 ''' \n",
    "                if(augment):\n",
    "                    images.append(np.fliplr(center_image))\n",
    "                    angles.append(-center_angle)\n",
    "                    '''\n",
    "                    images.append(np.fliplr(left_image))\n",
    "                    angles.append(-left_angle)\n",
    "                \n",
    "                    images.append(np.fliplr(right_image))\n",
    "                    angles.append(-right_angle)\n",
    "                    '''\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading csv file\n",
    "#reading provided data\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#loading csv file from zip\n",
    "archive = zipfile.ZipFile('/home/carnd/simulation_data/data.zip', 'r')\n",
    "csvFile = archive.open('data/driving_log.csv')\n",
    "\n",
    "\n",
    "lines=[] #reading csv files\n",
    "y=[] #the output for the steering angle\n",
    "X=[] #list for image output\n",
    "#reading csv file\n",
    "csvReader = pd.read_csv(csvFile)# the data.zip file uses headers\n",
    "correction = 0.3\n",
    "\n",
    "for line in csvReader.iterrows():\n",
    "    lines.append(line[1])\n",
    "    '''\n",
    "    center_img = archive.open('data/IMG/' + line[1][0].split('IMG/')[-1])\n",
    "    center_img = plt.imread(center_img) \n",
    "    \n",
    "    left_img = archive.open('data/IMG/' + line[1][1].split('IMG/')[1])\n",
    "    left_img = plt.imread(left_img)\n",
    "    \n",
    "    right_img = archive.open('data/IMG/' + line[1][2].split('IMG/')[1])\n",
    "    right_img = plt.imread(right_img)\n",
    "    \n",
    "    #X.append(np.concatenate((center_img, left_img, right_img),axis=2)) #creating a 9 channel input to be used by the network \n",
    "    X.append(center_img)\n",
    "    y.append(float(line[1][3]))\n",
    "    \n",
    "    \n",
    "    X.append(left_img)\n",
    "    y.append((float(line[1][3])+correction))\n",
    "    \n",
    "    X.append(right_img)\n",
    "    y.append((float(line[1][3])-correction))\n",
    "    \n",
    "    \n",
    "img_shape = X[0].shape\n",
    "\n",
    "#convert inputs and outputs to numpy array for keras\n",
    "X_train=np.array(X)\n",
    "y_train=np.array(y)\n",
    "'''\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2)\n",
    "img_shape = plt.imread(archive.open('data/IMG/' + lines[0][0].split('IMG/')[-1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#utilizing generators for reading data\n",
    "def generator(archive_in, samples, batch_size=32, augment=False):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            if(augment):\n",
    "                batch_samples = samples[offset:offset+math.ceil(batch_size/2)]\n",
    "            else:\n",
    "                batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            #loading files\n",
    "            for batch_sample in batch_samples:\n",
    "                name =  archive_in.open('data/IMG/' + batch_sample[0].split('IMG/')[-1])\n",
    "                center_image = plt.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                \n",
    "                name =  archive_in.open('data/IMG/' + batch_sample[1].split('IMG/')[-1])\n",
    "                left_image = plt.imread(name)\n",
    "                left_angle = float(batch_sample[3]) + correction\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                \n",
    "                name =  archive_in.open('data/IMG/' + batch_sample[2].split('IMG/')[-1])\n",
    "                right_image = plt.imread(name)\n",
    "                right_angle = float(batch_sample[3]) - correction\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "              \n",
    "                if(augment):\n",
    "                    images.append(np.fliplr(center_image))\n",
    "                    angles.append(-center_angle)\n",
    "                \n",
    "                    images.append(np.fliplr(left_image))\n",
    "                    angles.append(-left_angle)\n",
    "                \n",
    "                    images.append(np.fliplr(right_image))\n",
    "                    angles.append(-right_angle)\n",
    "                \n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#augmenting data by flipping\n",
    "X_flipped = np.fliplr(X_train)\n",
    "y_flipped = -y_train\n",
    "\n",
    "X_train = np.concatenate((X_train, X_flipped), axis=0)\n",
    "y_train = np.concatenate((y_train, y_flipped), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffling data\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Create & define NN model using keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Activation, Dense, Convolution2D, Dropout, Flatten, MaxPooling2D, Input, Merge, Lambda\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Cropping2D\n",
    "\n",
    "\n",
    "train_generator = generator(archive, train_samples, batch_size=35, augment=True)\n",
    "validation_generator = generator(archive, validation_samples, batch_size=35, augment=True)\n",
    "\n",
    "inp = Input(shape=img_shape)\n",
    "#gray = Lambda(lambda x: (0.21 * x[:,:,:,:1]) + (0.72 * x[:,:,:,1:2]) + (0.07 * x[:,:,:,-1:]))(inp)\n",
    "norm = Lambda(lambda x: np.divide(x - 127.5, 127.5))(inp)\n",
    "crop = Cropping2D(cropping=((50, 20), (0, 0)))(norm)\n",
    "c1 = Convolution2D(3, nb_row=5, nb_col=5, subsample=(1,1), border_mode='same')(crop)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2))(c1)\n",
    "c1a = Activation('relu')(c1p)\n",
    "c2 = Convolution2D(24, nb_row=5, nb_col=5, subsample=(1,1), border_mode='same')(c1)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2))(c2)\n",
    "c2a = Activation('relu')(c2p)\n",
    "c3 = Convolution2D(36, nb_row=5, nb_col=5, subsample=(1,1), border_mode='same')(c2a)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2))(c3)\n",
    "c3a = Activation('relu')(c3p) \n",
    "c4 = Convolution2D(48, nb_row=5, nb_col=5, subsample=(1,1), border_mode='same')(c3a)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "c4a = Activation('relu')(c4p)\n",
    "c5 = Convolution2D(64, nb_row=3, nb_col=3, subsample=(1,1), border_mode='same')(c4a)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2))(c5)\n",
    "c5a = Activation('relu')(c5p)\n",
    "c6 = Convolution2D(64, nb_row=3, nb_col=3, subsample=(1,1), border_mode='same')(c5a)\n",
    "c6p = MaxPooling2D(pool_size=(2, 2))(c6)\n",
    "c6a = Activation('relu')(c6p) \n",
    "#c7 = Convolution2D(64, nb_row=3, nb_col=3, subsample=(1,1), border_mode='same')(c6a)\n",
    "#c7p = MaxPooling2D(pool_size=(2, 2))(c7)\n",
    "#c7a = Activation('relu')(c7p) \n",
    "\n",
    "#flatc2 = Flatten()(c2a)\n",
    "#flatc3 = Flatten()(c3a)\n",
    "flatc5 = Flatten()(c5a)\n",
    "flatc6 = Flatten()(c6a)\n",
    "#flatc7 = Flatten()(c7a)\n",
    "flat = Merge(mode='concat')([flatc5, flatc6])\n",
    "\n",
    "f1 = Dense(1064)(flat)\n",
    "f1a = Activation('relu')(f1)\n",
    "f1d = Dropout(0.5)(f1a)\n",
    "f2 = Dense(100)(f1d)\n",
    "f2a = Activation('relu')(f2)\n",
    "f2d = Dropout(0.5)(f2a)\n",
    "f3 = Dense(50)(f2d)\n",
    "f3a = Activation('relu')(f3)\n",
    "f3d = Dropout(0.5)(f3a)\n",
    "out = Dense(1)(f3d)\n",
    "         \n",
    "model = Model(inp, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create & define NN model using keras - Sequential approach\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from keras.layers import Activation, Dense, Convolution2D, Dropout, Flatten, MaxPooling2D, Input, Merge, Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Lambda(lambda x: (0.21 * x[:,:,:,:1]) + (0.72 * x[:,:,:,1:2]) + (0.07 * x[:,:,:,-1:])))\n",
    "model.add(Lambda(lambda x: np.divide(x - 128, 128), input_shape=img_shape))\n",
    "model.add(Convolution2D(16, nb_row=3, nb_col=3, subsample=(2,2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, nb_row=3, nb_col=3, subsample=(2,2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train NN model\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator, validation_generator, nb_epoch=10, batch_size=128, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "43452/43467 [============================>.] - ETA: 0s - loss: 0.1465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43488/43467 [==============================] - 523s - loss: 0.1465 - val_loss: 0.1024\n",
      "Epoch 2/7\n",
      "43488/43467 [==============================] - 509s - loss: 0.1049 - val_loss: 0.0765\n",
      "Epoch 3/7\n",
      "43488/43467 [==============================] - 496s - loss: 0.0913 - val_loss: 0.0704\n",
      "Epoch 4/7\n",
      "43488/43467 [==============================] - 502s - loss: 0.0842 - val_loss: 0.0606\n",
      "Epoch 5/7\n",
      "43488/43467 [==============================] - 505s - loss: 0.0738 - val_loss: 0.0573\n",
      "Epoch 6/7\n",
      "43488/43467 [==============================] - 501s - loss: 0.0710 - val_loss: 0.0523\n",
      "Epoch 7/7\n",
      "43488/43467 [==============================] - 503s - loss: 0.0634 - val_loss: 0.0455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdceabccf98>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the NN generator model\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit_generator(train_generator, samples_per_epoch= len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving the model for future use\n",
    "model.save('modelfinal5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('what')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
