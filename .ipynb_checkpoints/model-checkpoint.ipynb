{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data from zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading csv file\n",
    "#reading myData\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#loading csv file from zip\n",
    "archive = zipfile.ZipFile('/home/carnd/simulation_data/allDataFinal.zip', 'r')\n",
    "csvFile = archive.open('driving_log.csv')\n",
    "\n",
    "lines=[] \n",
    "\n",
    "#reading csv file\n",
    "csvReader = pd.read_csv(csvFile, header=None)# the myData.zip file does not use headers\n",
    "correction = 0.2\n",
    "\n",
    "for line in csvReader.iterrows():\n",
    "    lines.append(line[1])\n",
    "\n",
    "dir1 = 'IMG/' + lines[0][0].split('IMG\\\\')[-1]\n",
    "dir2 = 'IMG/' + lines[0][0].split('IMG/')[-1]\n",
    "if dir1 in archive.namelist():\n",
    "    img_dir =  archive_in.open(dir1)\n",
    "else:\n",
    "    img_dir =  archive_in.open(dir2)\n",
    "img_shape = plt.imread(archive.open(img_dir)[-1])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing and balancing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'random' has no attribute 'randint16'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ba5b1112d34c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'random' has no attribute 'randint16'"
     ]
    }
   ],
   "source": [
    "#Visualizing random samples of the data set images along with their corresponding steering angles\n",
    "import random\n",
    "\n",
    "n_visualize=10\n",
    "n_rows = 5\n",
    "n_columns = math.ceil(n_visualize/n_rows)\n",
    "\n",
    "x = random.sample(range(0,len(lines)), n_visualize)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.suptitle('Random image samples', fontsize=16)\n",
    "\n",
    "for i in range(0, n_visualize):\n",
    "    plt.subplot(n_rows,n_columns,i+1)\n",
    "    \n",
    "    dir1 = 'IMG/' + lines[x[i]][0].split('IMG\\\\')[-1]\n",
    "    dir2 = 'IMG/' + lines[x[i]][0].split('IMG/')[-1]\n",
    "    if dir1 in archive.namelist():\n",
    "        img_dir =  archive.open(dir1)\n",
    "    else:\n",
    "        img_dir =  archive.open(dir2)\n",
    "    img = plt.imread(img_dir)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Steering angle: {}'.format(float(lines[x[i]][3])))\n",
    "\n",
    "plt.savefig('figures/data_samples.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Categorazing the Data present in the training set\n",
    "\n",
    "ranges = np.zeros(10, np.int16) #a counter of number of data points with certain ranges of steering angles\n",
    "\n",
    "for line in lines:\n",
    "    steering_angle = line[3]\n",
    "    for i in range(0,10):\n",
    "        if(steering_angle>(1-0.2*(i+1)) and steering_angle<(1-0.2*i)):\n",
    "            ranges[i]= ranges[i]+1 #incrementing the desired counter if steering angle falls within range\n",
    "            break\n",
    "            \n",
    "plt.bar(np.linspace(0.9,-0.9,10),ranges, 0.2) #bar plot of range of steering angles in training set\n",
    "plt.title('Data representation per steering angle range')\n",
    "plt.xlabel('Steering angles')\n",
    "plt.ylabel('Number of samples')\n",
    "\n",
    "plt.savefig('figures/data_before_balancing.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As seen above, there are a lot of data points around a steering angle of zero, and much less for larger steering angles\n",
    "#The code below either randomly deletes or repeats data based on the range the steering angle falls within \n",
    "#in order to reach a more balanced representation of data\n",
    "for i in reversed(range(len(lines))):\n",
    "    \n",
    "    steering = float(lines[i][3])\n",
    "    \n",
    "    if(steering>0 and abs(steering<0.2):\n",
    "        keep_probs = random.random(); \n",
    "        if(keep_probs>0.45):\n",
    "            del lines[i] \n",
    "    elif(steering>-0.2 and steering<=0):\n",
    "        keep_probs = random.random();\n",
    "        if(keep_probs>0.22):\n",
    "            del lines[i] \n",
    "    elif(steering>-0.4 and steering<=-0.2):\n",
    "        keep_probs = random.random();\n",
    "        if(keep_probs>0.8):\n",
    "            del lines[i] \n",
    "    elif(steering<-0.8 or steering>0.8):\n",
    "        for j in range(8):\n",
    "            lines.append(lines[i])\n",
    "    elif(steering<-0.6 or steering>0.6):\n",
    "        for j in range(2):\n",
    "            lines.append(lines[i])\n",
    "    elif(steering<-0.5 or steering>0.5):\n",
    "        for j in range(2):\n",
    "            lines.append(lines[i])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdcff2e32e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing and categorazing the Data present in the training set upon manipulation\n",
    "\n",
    "ranges = np.zeros(10, np.int16)#a counter of number of data points with certain ranges of steering angles\n",
    "\n",
    "for line in lines:\n",
    "    steering = line[3]\n",
    "    for i in range(0,10):\n",
    "        if(steering>(1-0.2*(i+1)) and steering<(1-0.2*i)):\n",
    "            ranges[i]= ranges[i]+1\n",
    "            break\n",
    "plt.bar(np.linspace(0.9,-0.9,10),ranges, 0.2)\n",
    "plt.title('Data representation per steering angle range (after balancing)')\n",
    "plt.xlabel('Steering angles')\n",
    "plt.ylabel('Number of samples')\n",
    "\n",
    "plt.savefig('figures/data_after_balancing.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffling and spliting the data\n",
    "lines = shuffle(lines)\n",
    "train_samples, remaining_samples = train_test_split(lines, test_size=0.4)\n",
    "valid_samples, test_samples(remaining_samples, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(train_samples)\n",
    "n_valid = len(validation_samples)\n",
    "n_test = len(test_samples)\n",
    "\n",
    "print(\"length of the training set is: {}\".format(n_train))\n",
    "print(\"length of the training set is: {}\".format(n_valid))\n",
    "print(\"length of the training set is: {}\".format(n_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generator for the Data set\n",
    "#The data generator is utilized for efficient use of memory by utilizing the 'yield' command.\n",
    "\n",
    "#this function basically accepts lines from the csv file and returns the corresponding image \n",
    "#and a flipped version of the image along with corresponding steering angles\n",
    "\n",
    "def generator(archive_in, samples, batch_size=32, augment=False):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "        \n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            \n",
    "            images = []\n",
    "            angles = []\n",
    "            #loading files\n",
    "            for batch_sample in batch_samples:\n",
    "                dir1 = 'IMG/' + batch_sample[0].split('IMG\\\\')[-1]\n",
    "                dir2 = 'IMG/' + batch_sample[0].split('IMG/')[-1]\n",
    "                if dir1 in archive.namelist():\n",
    "                    img_dir =  archive_in.open(dir1)\n",
    "                elif dir2 in archive.namelist():\n",
    "                    img_dir =  archive_in.open(dir2)\n",
    "                center_image = plt.imread(img_dir)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                \n",
    "                if(augment):\n",
    "                    images.append(np.fliplr(center_image))\n",
    "                    angles.append(-center_angle)\n",
    "                    \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing packages and obtaining data\n",
    "import tensorflow as tf\n",
    "from keras.layers import Activation, Dense, Convolution2D, Dropout, Flatten, MaxPooling2D, Input, Merge, Lambda\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Cropping2D\n",
    "\n",
    "#obtaining training and validation data\n",
    "train_generator = generator(archive, train_samples, batch_size=32, augment=True)\n",
    "validation_generator = generator(archive, validation_samples, batch_size=32, augment=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "\n",
    "#The model defined here consists of six convolutional layers with max pooling and relu activation\n",
    "#followed by 3 fully connected layers also with relu activation and dropout\n",
    "#The output of the last two convolutional layers are flattened and used as inputs to the fully connected layers\n",
    "\n",
    "\n",
    "inp = Input(shape=img_shape)\n",
    "\n",
    "#normalizing data\n",
    "norm = Lambda(lambda x: np.divide(x - 127.5, 127.5))(inp)\n",
    "\n",
    "#cropping image to desired region\n",
    "crop = Cropping2D(cropping=((50, 20), (0, 0)))(norm)\n",
    "\n",
    "#first convolutional layer with max pooling and relu activattion\n",
    "c1 = Convolution2D(3, nb_row=5, nb_col=5, subsample=(1,1), border_mode='same')(crop)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2))(c1)\n",
    "c1a = Activation('relu')(c1p)\n",
    "\n",
    "#second convolutional layer with max pooling and relu activattion\n",
    "c2 = Convolution2D(24, nb_row=5, nb_col=5, subsample=(1,1), border_mode='same')(c1)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2))(c2)\n",
    "c2a = Activation('relu')(c2p)\n",
    "\n",
    "#third convolutional layer with max pooling and relu activattion\n",
    "c3 = Convolution2D(36, nb_row=5, nb_col=5, subsample=(1,1), border_mode='same')(c2a)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2))(c3)\n",
    "c3a = Activation('relu')(c3p) \n",
    "\n",
    "#fourth convolutional layer with max pooling and relu activattion\n",
    "c4 = Convolution2D(48, nb_row=5, nb_col=5, subsample=(1,1), border_mode='same')(c3a)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "c4a = Activation('relu')(c4p)\n",
    "\n",
    "#fifth convolutional layer with max pooling and relu activattion\n",
    "c5 = Convolution2D(64, nb_row=3, nb_col=3, subsample=(1,1), border_mode='same')(c4a)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2))(c5)\n",
    "c5a = Activation('relu')(c5p)\n",
    "\n",
    "#sixth convolutional layer with max pooling and relu activattion\n",
    "c6 = Convolution2D(64, nb_row=3, nb_col=3, subsample=(1,1), border_mode='same')(c5a)\n",
    "c6p = MaxPooling2D(pool_size=(2, 2))(c6)\n",
    "c6a = Activation('relu')(c6p) \n",
    "\n",
    "#flattening and concatinating output of last two layers\n",
    "flatc5 = Flatten()(c5a)\n",
    "flatc6 = Flatten()(c6a)\n",
    "flat = Merge(mode='concat')([flatc5, flatc6])\n",
    "\n",
    "#first fully connected layer\n",
    "f1 = Dense(1064)(flat)\n",
    "f1a = Activation('relu')(f1)\n",
    "f1d = Dropout(0.5)(f1a)\n",
    "\n",
    "#second fully connected layer\n",
    "f2 = Dense(100)(f1d)\n",
    "f2a = Activation('relu')(f2)\n",
    "f2d = Dropout(0.5)(f2a)\n",
    "\n",
    "#third fully connected layer and regression layer\n",
    "f3 = Dense(50)(f2d)\n",
    "f3a = Activation('relu')(f3)\n",
    "f3d = Dropout(0.5)(f3a)\n",
    "out = Dense(1)(f3d)\n",
    " \n",
    "#defining model\n",
    "model = Model(inp, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "43452/43467 [============================>.] - ETA: 0s - loss: 0.1465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43488/43467 [==============================] - 523s - loss: 0.1465 - val_loss: 0.1024\n",
      "Epoch 2/7\n",
      "43488/43467 [==============================] - 509s - loss: 0.1049 - val_loss: 0.0765\n",
      "Epoch 3/7\n",
      "43488/43467 [==============================] - 496s - loss: 0.0913 - val_loss: 0.0704\n",
      "Epoch 4/7\n",
      "43488/43467 [==============================] - 502s - loss: 0.0842 - val_loss: 0.0606\n",
      "Epoch 5/7\n",
      "43488/43467 [==============================] - 505s - loss: 0.0738 - val_loss: 0.0573\n",
      "Epoch 6/7\n",
      "43488/43467 [==============================] - 501s - loss: 0.0710 - val_loss: 0.0523\n",
      "Epoch 7/7\n",
      "43488/43467 [==============================] - 503s - loss: 0.0634 - val_loss: 0.0455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdceabccf98>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the NN model\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit_generator(train_generator, samples_per_epoch = n_train, validation_data=validation_generator, nb_val_samples = n_valid, nb_epoch=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " model.evaluate_generator(test_generator, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model for future use\n",
    "model.save('modelfinal5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
